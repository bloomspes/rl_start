# [RL스터디] 0 ~ 49 page

# [Summary]

## 1. 강화학습 개념

- 행동심리학의 `'강화'` + `머신러닝` 기법에 바탕을 두고 있다.
- `Agent`가 `MDP`를 통해 보상을 얻는 과정으로 학습이 이루어진다.
    - Break-Out 게임 >> 강화학습과 MDP를 이해하기에 좋은 대표적인 사례.
        - MDP를 구성하는 모든 요인은 `시간`의 영향을 받을 수 밖에 없다.
        - Agent의 행동의 결과물인 **보상(Reward)**은 시간이 지날수록 `감가율`이 적용이 되기 때문이다.
        - 결국, 최적 정책을 빠르게 찾아가는 과정은 `Agent`가 **시간 대비 가치함수의 결과 값 중에서 큰 값을 선별해 가는 과정**이다.

## 2. Why we should learn to understand of DQN?

### 2.1 Q-Learning

- 각 현재 상태(s)에 대해, Agent의 목표는 보상(R)의 총합을 최대로 하는데에 있다.
- 학습해야 할 경우의 수를 `Q-table`에 기록한다.
    - 각각의 시나리오에서 고려해야 할 변수가 많거나 수행하는 학습 해야할 Q-table의 크기가 급격히 늘어나는 단점이 있다.
- 

### 2.2 Deep-Learning

- Neural Network의 등장
    - Q-table의 문제점을 보완할 수 있다. **입력층(Input Layer), 은닉층(Hidden Layer), 출력층(Output Layer)**으로 구분 된다.
- 역전파(Backpropagation)
    - 결과 값을 통해서 다시 Input 방향으로 오차를 다시 보내 가중치를 업데이트 하는 원리이다.
        - `epoch`를 늘릴 수록 가중치가 계속 업데이트 되면서 점점 오차가 줄어든다.

### 2.3 DQN(Deep-Q-Network)

- 딥러닝을 강화학습에 적용하는 여러 문제를 해결했다고 한다. (추후 업데이트 예정)
- 전처리, 모델 최적화, 합성곱 신경망, 최적화, 비용 함수, Experiance Replay 과정을 거친다.

## 3. 느낀점

- 딥러닝이 등장한 배경에 대해서 history를 찾아보는 것이 필요하단 생각이 들었다.
- 간단한 실습 예제로 '공 주고 받기 게임'을 구현 중이다...